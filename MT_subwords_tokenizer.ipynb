{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT.subwords_tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3291005a0a6b422688973c1f24cba49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7952cd0c9b594a16bc220848761f464a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff4d2eedf5204dc7959db9636200ebc1",
              "IPY_MODEL_979fa3d1c5e34d409c137219077f20ca"
            ]
          }
        },
        "7952cd0c9b594a16bc220848761f464a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff4d2eedf5204dc7959db9636200ebc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f7446cabc6549a5b16a3b3f9e5e30b6",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d01083849e34dd0b6de8351a99f484a"
          }
        },
        "979fa3d1c5e34d409c137219077f20ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4b13d37b0f44a618ce69fefed033c2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [01:23&lt;00:00, 83.48s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16e9e567ad66404ca5b1ab70589292dc"
          }
        },
        "4f7446cabc6549a5b16a3b3f9e5e30b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d01083849e34dd0b6de8351a99f484a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4b13d37b0f44a618ce69fefed033c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16e9e567ad66404ca5b1ab70589292dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "169365bf099342dd98275028df318c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8fca7f4ef3145baa6cfab14a76fe0f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d69464dcbb14ea0a1b63cdb73a14d07",
              "IPY_MODEL_8d25b173cd4d4b1b8811c86d15f2ec56"
            ]
          }
        },
        "e8fca7f4ef3145baa6cfab14a76fe0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d69464dcbb14ea0a1b63cdb73a14d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f982b299a8b4385a40d7b67a39813a1",
            "_dom_classes": [],
            "description": "Dl Size...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bd9029e01b745f9a12862e6c0fbdc77"
          }
        },
        "8d25b173cd4d4b1b8811c86d15f2ec56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5dca686856d5485e91dc25576062a509",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1247/1247 [01:23&lt;00:00, 14.95 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05557fcd372449fa9333ff70d62f504d"
          }
        },
        "7f982b299a8b4385a40d7b67a39813a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bd9029e01b745f9a12862e6c0fbdc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dca686856d5485e91dc25576062a509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05557fcd372449fa9333ff70d62f504d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26bebef403e3402caa52aed7e200921b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dec33b4d04fb4b6f8eacb30a15316520",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ba1f54b8a4b14a27a643441a9cc8b2cb",
              "IPY_MODEL_df3847ef2acc4ba488bba5f898782254"
            ]
          }
        },
        "dec33b4d04fb4b6f8eacb30a15316520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba1f54b8a4b14a27a643441a9cc8b2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57e1222d0a454d35ae3a6d93be4dde3f",
            "_dom_classes": [],
            "description": "Extraction completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9e3b17879fe4b8e91aa9c433a69eee2"
          }
        },
        "df3847ef2acc4ba488bba5f898782254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45e30ccaa8cc4a2097c39c19d67bf933",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [01:23&lt;00:00, 83.33s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea42bdc587c94dafb8c7e0c89f5c6a0c"
          }
        },
        "57e1222d0a454d35ae3a6d93be4dde3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9e3b17879fe4b8e91aa9c433a69eee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45e30ccaa8cc4a2097c39c19d67bf933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea42bdc587c94dafb8c7e0c89f5c6a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af71c0d6984941359811ba432dbed408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2909d76c2c4943c2a83b07506ad41310",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5231aac0eb7544b391456b09a12bab25",
              "IPY_MODEL_9377db2588f04f418dda14df755f8ed6"
            ]
          }
        },
        "2909d76c2c4943c2a83b07506ad41310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5231aac0eb7544b391456b09a12bab25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_10bae2a8b0ac4ace92ee363705e908b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04511641a07146b5831f15b40c72fc32"
          }
        },
        "9377db2588f04f418dda14df755f8ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_282bbe4cc4ff4a8892712aa0c0e9b9de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16264448/0 [1:06:22&lt;00:00, 4313.94 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d82b69572c544f090bc3ba2bf426f47"
          }
        },
        "10bae2a8b0ac4ace92ee363705e908b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04511641a07146b5831f15b40c72fc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "282bbe4cc4ff4a8892712aa0c0e9b9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d82b69572c544f090bc3ba2bf426f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de7d37b7630c4a24b7373417b458d732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b78a83ad4bf4a20a28da47d9554f6d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3867fa9273cf41ae9b594334d141437d",
              "IPY_MODEL_f9f9da8537a142e3a3a11a96e587e7d7"
            ]
          }
        },
        "8b78a83ad4bf4a20a28da47d9554f6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3867fa9273cf41ae9b594334d141437d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_de55ce0ce0de462a97857af405d85c22",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 16264448,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16248286,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41788f0b905144149d64f5a76c3401ac"
          }
        },
        "f9f9da8537a142e3a3a11a96e587e7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c58cbc5613d2483487873bbf396e2ad8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16248286/16264448 [03:50&lt;00:00, 84938.03 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54b0b6ad336b463698dc6d5d6c49491d"
          }
        },
        "de55ce0ce0de462a97857af405d85c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41788f0b905144149d64f5a76c3401ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c58cbc5613d2483487873bbf396e2ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54b0b6ad336b463698dc6d5d6c49491d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmith1138/MachineTranslation/blob/main/MT_subwords_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jmjh290raIky"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/tensorflow_text/subwords_tokenizer\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/examples/subwords_tokenizer.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/examples/subwords_tokenizer.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/examples/subwords_tokenizer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES8iTKcdPCLt"
      },
      "source": [
        "# Subword tokenizers\n",
        "\n",
        "This tutorial demonstrates how to generate a subword vocabulary from a dataset, and use it to build a `text.BertTokenizer` from the vocabulary.\n",
        "\n",
        "The main advantage of a subword tokenizer is that it interpolates between word-based and character-based tokenization. Common words get a slot in the vocabulary, but the tokenizer can fall back to word pieces and individual characters for unknown words.\n",
        "\n",
        "Objective: At the end of this tutorial you'll have built a complete end-to-end wordpiece tokenizer and detokenizer from scratch, and saved it as a `saved_model` that you can load and use in this [translation tutorial](https://tensorflow.org/tutorials/text/transformer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHfrtG1YPJdR"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIMuBnQO6ZoV"
      },
      "source": [
        "The `tensorflow_text` package includes TensorFlow implementations of many common tokenizers. This includes three subword-style tokenizers:\n",
        "\n",
        "* `text.BertTokenizer` - The `BertTokenizer` class is a higher level interface. It includes BERT's token splitting algorithm and a `WordPieceTokenizer`. It takes **sentences** as input and returns **token-IDs**.\n",
        "* `text.WordpeiceTokenizer` - The `WordPieceTokenizer` class is a lower level interface. It only implements the [WordPiece algorithm](#applying_wordpiece). You must standardize and split the text into words before calling it. It takes **words** as input and returns token-IDs.\n",
        "* `text.SentencepieceTokenizer` - The `SentencepieceTokenizer` requires a more complex setup. Its initializer requires a pre-trained sentencepiece model. See the [google/sentencepiece repository](https://github.com/google/sentencepiece#train-sentencepiece-model) for instructions on how to build one of these models. It can accept **sentences** as input when tokenizing.\n",
        "\n",
        "This tutorial builds a Wordpiece vocabulary in a top down manner, starting from existing words. This process doesn't work for Japanese, Chinese, or Korean since these languages don't have clear multi-character units. To tokenize these languages conside using `text.SentencepieceTokenizer`, `text.UnicodeCharTokenizer` or [this approach](https://tfhub.dev/google/zh_segmentation/1). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swymtxpl7W7w"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgTolJBriF1a",
        "outputId": "c810a08f-802f-4ca4-b924-df8e34a58373"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFG0NDRu5mYQ"
      },
      "source": [
        "!pip install -q tensorflow_datasets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUy1jBj1Q6dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cece3f-fb99-45c4-93dd-39e0041fd907"
      },
      "source": [
        "# 2.5.0.dev20210325 => avoid binary incompatibilities until 2.5 is out.\n",
        "\n",
        "# `BertTokenizer.detokenize` is not in `tf-text` stable yet (currently 2.4.3).\n",
        "!pip install -q tensorflow_text_nightly==2.5.0.dev20210325\n",
        "# tf-text-nightly resquires tf-nightly\n",
        "!pip install -q tf-nightly==2.5.0.dev20210325"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4MB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.1MB 25kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 41.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 38.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.1MB 22.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0MB 37.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 40.1MB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjJJyJTZYebt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df82b49-01bb-4173-9eb8-cc3362d8f883"
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import tempfile\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enabling eager execution\n",
            "INFO:tensorflow:Enabling v2 tensorshape\n",
            "INFO:tensorflow:Enabling resource variables\n",
            "INFO:tensorflow:Enabling tensor equality\n",
            "INFO:tensorflow:Enabling control flow v2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZi9RstHxO_Z"
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "pwd = pathlib.Path.cwd()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzJbGA5N5mXr"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9TeTd47j8p"
      },
      "source": [
        "Fetch the Portuguese/English translation dataset from [tfds](https://tensorflow.org/datasets):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDaAOTKHNy8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367,
          "referenced_widgets": [
            "3291005a0a6b422688973c1f24cba49f",
            "7952cd0c9b594a16bc220848761f464a",
            "ff4d2eedf5204dc7959db9636200ebc1",
            "979fa3d1c5e34d409c137219077f20ca",
            "4f7446cabc6549a5b16a3b3f9e5e30b6",
            "9d01083849e34dd0b6de8351a99f484a",
            "a4b13d37b0f44a618ce69fefed033c2b",
            "16e9e567ad66404ca5b1ab70589292dc",
            "169365bf099342dd98275028df318c91",
            "e8fca7f4ef3145baa6cfab14a76fe0f7",
            "9d69464dcbb14ea0a1b63cdb73a14d07",
            "8d25b173cd4d4b1b8811c86d15f2ec56",
            "7f982b299a8b4385a40d7b67a39813a1",
            "5bd9029e01b745f9a12862e6c0fbdc77",
            "5dca686856d5485e91dc25576062a509",
            "05557fcd372449fa9333ff70d62f504d",
            "26bebef403e3402caa52aed7e200921b",
            "dec33b4d04fb4b6f8eacb30a15316520",
            "ba1f54b8a4b14a27a643441a9cc8b2cb",
            "df3847ef2acc4ba488bba5f898782254",
            "57e1222d0a454d35ae3a6d93be4dde3f",
            "b9e3b17879fe4b8e91aa9c433a69eee2",
            "45e30ccaa8cc4a2097c39c19d67bf933",
            "ea42bdc587c94dafb8c7e0c89f5c6a0c",
            "af71c0d6984941359811ba432dbed408",
            "2909d76c2c4943c2a83b07506ad41310",
            "5231aac0eb7544b391456b09a12bab25",
            "9377db2588f04f418dda14df755f8ed6",
            "10bae2a8b0ac4ace92ee363705e908b5",
            "04511641a07146b5831f15b40c72fc32",
            "282bbe4cc4ff4a8892712aa0c0e9b9de",
            "4d82b69572c544f090bc3ba2bf426f47",
            "de7d37b7630c4a24b7373417b458d732",
            "8b78a83ad4bf4a20a28da47d9554f6d8",
            "3867fa9273cf41ae9b594334d141437d",
            "f9f9da8537a142e3a3a11a96e587e7d7",
            "de55ce0ce0de462a97857af405d85c22",
            "41788f0b905144149d64f5a76c3401ac",
            "c58cbc5613d2483487873bbf396e2ad8",
            "54b0b6ad336b463698dc6d5d6c49491d"
          ]
        },
        "outputId": "3d956dda-5d1e-492d-94b5-d97d030cf625"
      },
      "source": [
        "#examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
        "#                               as_supervised=True)\n",
        "#train_examples, val_examples = examples['train'], examples['validation']  \n",
        "examplesDe, metadataDe = tfds.load('para_crawl/ende_plain_text', with_info=True, as_supervised=True)\n",
        "print(examplesDe.keys())\n",
        "train_examples = examplesDe['train']#, examplesDe['validation']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset para_crawl/ende_plain_text/1.0.0 (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/para_crawl/ende_plain_text/1.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3291005a0a6b422688973c1f24cba49f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "169365bf099342dd98275028df318c91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26bebef403e3402caa52aed7e200921b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af71c0d6984941359811ba432dbed408",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rShuffling and writing examples to /root/tensorflow_datasets/para_crawl/ende_plain_text/1.0.0.incompleteQDUFBB/para_crawl-train.tfrecord\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de7d37b7630c4a24b7373417b458d732",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16264448.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: TFDS encoder are deprecated and will be removed soon. Please use `tensorflow_text` instead with the plain text dataset.\n",
            "\u001b[1mDataset para_crawl downloaded and prepared to /root/tensorflow_datasets/para_crawl/ende_plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "dict_keys(['train'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GHc3O2W8Hgg"
      },
      "source": [
        "This dataset produces Portuguese/English sentence pairs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_ezZT8w8GqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00710f1d-f404-412a-a485-2cdb2835584f"
      },
      "source": [
        "for de, en in train_examples.take(1):\n",
        "  print(\"German: \", de.numpy().decode('utf-8'))\n",
        "  print(\"English:   \", en.numpy().decode('utf-8'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "German:  Pictures of Quebec : roofs of Quebec\n",
            "English:    Fotos von Quebec - Dächer von Quebec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNGwm45vKttj"
      },
      "source": [
        "Note a few things about the example sentences above:\n",
        "* They're lower case.\n",
        "* There are spaces around the punctuation.\n",
        "* It's not clear if or what unicode normalization is being used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm5Eah5F6B1I"
      },
      "source": [
        "train_en = train_examples.map(lambda de, en: en)\n",
        "train_de = train_examples.map(lambda de, en: de)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCD57yALsF0D"
      },
      "source": [
        "## Generate the vocabulary\n",
        "\n",
        "This section generates a wordpiece vocabulary from a dataset. If you already have a vocabulary file and just want to see how to build a `text.BertTokenizer` or `text.Wordpiece` tokenizer with it then you can skip ahead to the [Build the tokenizer](#build_the_tokenizer) section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4CX7_KlO8lX"
      },
      "source": [
        "Note: The vocabulary generation code used in this tutorial is optimized for **simplicity**. If you need a more scalable solution consider using the Apache Beam implementation available in [tools/wordpiece_vocab/generate_vocab.py](https://github.com/tensorflow/text/blob/master/tensorflow_text/tools/wordpiece_vocab/generate_vocab.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R74W3QabgWmX"
      },
      "source": [
        "The vocabulary generation code is included in the `tensorflow_text` pip package. It is not imported by default , you need to manually import it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqX1fYdpnLS2"
      },
      "source": [
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaWSnj8xFgI7"
      },
      "source": [
        "The `bert_vocab.bert_vocab_from_dataset` function will generate the vocabulary. \n",
        "\n",
        "There are many arguments you can set to adjust its behavior. For this tutorial, you'll mostly use the defaults. If you want to learn more about the options, first read about [the algorithm](#algorithm), and then have a look at [the code](https://github.com/tensorflow/text/blob/master/tensorflow_text/tools/wordpiece_vocab/bert_vocab_from_dataset.py).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gTty2Wh-dHm"
      },
      "source": [
        "This takes about 2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwFzYjBy-h8W"
      },
      "source": [
        "bert_tokenizer_params=dict(lower_case=True)\n",
        "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "bert_vocab_args = dict(\n",
        "    # The target vocabulary size\n",
        "    vocab_size = 8000,\n",
        "    # Reserved tokens that must be included in the vocabulary\n",
        "    reserved_tokens=reserved_tokens,\n",
        "    # Arguments for `text.BertTokenizer`\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "    learn_params={},\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMN6Lli_3sJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018dfc22-6cf2-4176-f38a-de061e1dc2e0"
      },
      "source": [
        "%%time\n",
        "de_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_de.batch(1000).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2h 13min 9s, sys: 15min, total: 2h 28min 10s\n",
            "Wall time: 2h 10min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cl4d2O34gkH"
      },
      "source": [
        "Here are some slices of the resulting vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfaPmX54FvhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c31b7cb-aa67-4bff-f367-909cd8f94a94"
      },
      "source": [
        "print(de_vocab[:10])\n",
        "print(de_vocab[100:110])\n",
        "print(de_vocab[1000:1010])\n",
        "print(de_vocab[-10:])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', '\"', '#', '$', '%', '&']\n",
            "['ə', 'ʻ', 'ʼ', 'ʾ', 'ʿ', 'ˆ', 'ˇ', 'α', 'β', 'γ']\n",
            "['the', 'of', 'and', 'to', 'in', '##s', 'is', 'for', 'with', 'on']\n",
            "['##食', '##首', '##香', '##马', '##验', '##高', '##麦', '##黄', '##黑', '##齐']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owkP3wbYVQv0"
      },
      "source": [
        "Write a vocabulary file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY6v1ThkKDyZ"
      },
      "source": [
        "def write_vocab_file(filepath, vocab):\n",
        "  with open(filepath, 'w') as f:\n",
        "    for token in vocab:\n",
        "      print(token, file=f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_TR5U1xWvAV"
      },
      "source": [
        "write_vocab_file('de_vocab.txt', de_vocab)\n",
        "write_vocab_file('/content/drive/MyDrive/MT/de_vocab.txt', de_vocab)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ag3qcx54nii"
      },
      "source": [
        "Use that function to generate a vocabulary from the english data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3cMumvHWWtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ea44f3-bdec-491e-da99-86445917fa55"
      },
      "source": [
        "%%time\n",
        "en_vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_en.batch(1000).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10h 42min 56s, sys: 18min 4s, total: 11h 1min\n",
            "Wall time: 10h 44min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxOpzMd8ol5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e280f7-5603-4739-9341-5d95fab140d7"
      },
      "source": [
        "print(en_vocab[:10])\n",
        "print(en_vocab[100:110])\n",
        "print(en_vocab[1000:1010])\n",
        "print(en_vocab[-10:])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[PAD]', '[UNK]', '[START]', '[END]', '!', '\"', '#', '$', '%', '&']\n",
            "['œ', 'ǀ', 'ǂ', 'ǝ', 'ɑ', 'ɔ', 'ə', 'ɛ', 'ɦ', 'ɪ']\n",
            "['ist', 'fur', '##n', 'auf', 'des', 'im', 'eine', 'ein', 'es', 'dem']\n",
            "['##青', '##面', '##题', '##餐', '##香', '##體', '##高', '##鹵', '##龍', '##ꞌ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck3LG_f34wCs"
      },
      "source": [
        "Here are the two vocabulary files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfc2jxPznM6H"
      },
      "source": [
        "write_vocab_file('en_vocab.txt', en_vocab)\n",
        "write_vocab_file('/content/drive/MyDrive/MT/en_vocab.txt', en_vocab)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djehfEL6Zn-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d83b394-c151-4013-8ec4-570333f291e0"
      },
      "source": [
        "!ls *.txt"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en_vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb5ddYLTBJhk"
      },
      "source": [
        "## Build the tokenizer\n",
        "<a id=\"build_the_tokenizer\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qgp5gvR-2tQ"
      },
      "source": [
        "The `text.BertTokenizer` can be initialized by passing the vocabulary file's path as the first argument (see the section on [tf.lookup](#tf.lookup) for other options): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdMpt9ZEjVGu"
      },
      "source": [
        "de_tokenizer = text.BertTokenizer('/content/drive/MyDrive/MT/de_vocab.txt', **bert_tokenizer_params)\n",
        "en_tokenizer = text.BertTokenizer('/content/drive/MyDrive/MT/en_vocab.txt', **bert_tokenizer_params)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhPZafCUds86"
      },
      "source": [
        "Now you can use it to encode some text. Take a batch of 3 examples from the english data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKF0QJjtUm9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d8b112-adb1-44a1-bdd6-ec4f7787c456"
      },
      "source": [
        "for de_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  for ex in en_examples:\n",
        "    print(ex.numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Fotos von Quebec - D\\xc3\\xa4cher von Quebec'\n",
            "b'April 2007 In einer nicht so schockierenden, aber sehr relevanten Umfrage, entdeckte BtoBonline das die meisten E-Mail Vermarkter \\xe2\\x80\\x93 besonders die auf der business to business Seite- verzichten weiterhin auf die Pr\\xc3\\xbcfung Ihrer Kampagnen bevor sie Sie senden.'\n",
            "b'Tschekisten k\\xc3\\xb6nnen nicht \\xc3\\xbcber ihre eigene Nase hinausblicken [...], sie sind dabei, in gew\\xc3\\xb6hnliche Schlafm\\xc3\\xbctzen zu degenerieren und [...] sie wollen nicht die Direktiven des ZK erf\\xc3\\xbcllen. (S. 134)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9OEIBWopMxW"
      },
      "source": [
        "Run it through the `BertTokenizer.tokenize` method. Initially, this returns a `tf.RaggedTensor` with axes `(batch, word, word-piece)`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeTM81lAc8q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fa8ed1-79d1-42d9-b80d-6ae7e0380541"
      },
      "source": [
        "# Tokenize the examples -> (batch, word, word-piece)\n",
        "token_batch = en_tokenizer.tokenize(en_examples)\n",
        "# Merge the word and word-piece axes -> (batch, tokens)\n",
        "token_batch = token_batch.merge_dims(-2,-1)\n",
        "\n",
        "for ex in token_batch.to_list():\n",
        "  print(ex)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1453, 991, 58, 1594, 1296, 1107, 16, 6101, 1018, 991, 58, 1594, 1296, 1107]\n",
            "[1501, 1578, 990, 1030, 1011, 1050, 60, 1190, 3957, 5245, 15, 1049, 1077, 59, 1177, 993, 1799, 1965, 1026, 3960, 15, 4991, 993, 43, 2123, 3678, 1002, 2924, 998, 988, 1463, 46, 16, 1543, 63, 1018, 2562, 1018, 368, 1438, 988, 1003, 989, 3185, 2755, 3185, 1195, 16, 63, 1018, 5969, 2352, 2302, 1003, 988, 2873, 1104, 5974, 1002, 1810, 992, 992, 2436, 17]\n",
            "[61, 1895, 2399, 1206, 1042, 1011, 1029, 1046, 1906, 55, 2272, 1851, 2713, 995, 36, 17, 17, 17, 38, 15, 992, 1015, 1297, 15, 990, 48, 993, 4120, 993, 60, 1190, 1586, 1129, 1047, 4642, 996, 1233, 1218, 4912, 1234, 987, 36, 17, 17, 17, 38, 992, 1375, 1011, 988, 1314, 2103, 1004, 67, 1109, 3054, 17, 11, 60, 17, 1316, 1257, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbdIaW6kX8hu"
      },
      "source": [
        "If you replace the token IDs with their text representations (using `tf.gather`) you can see that in the first example the words `\"searchability\"` and  `\"serendipity\"` have been decomposed into `\"search ##ability\"` and `\"s ##ere ##nd ##ip ##ity\"`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA6nKYx5U3Nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8204b5-2130-44cb-8672-56ba850a37f5"
      },
      "source": [
        "# Lookup each token id in the vocabulary.\n",
        "txt_tokens = tf.gather(en_vocab, token_batch)\n",
        "# Join with spaces.\n",
        "tf.strings.reduce_join(txt_tokens, separator=' ', axis=-1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
              "array([b'fotos von q ##ue ##be ##c - dach ##er von q ##ue ##be ##c',\n",
              "       b'april 2007 in einer nicht so s ##ch ##ock ##ierenden , aber sehr r ##el ##e ##va ##nten um ##frage , entdeckt ##e b ##to ##bo ##n ##line das die meisten e - mail v ##er ##markt ##er \\xe2\\x80\\x93 besonders die auf der business to business seite - v ##er ##zi ##chten weiterhin auf die prufung ihrer kampagne ##n bevor sie sie senden .',\n",
              "       b't ##sche ##ki ##sten konnen nicht uber ihre eigene n ##ase hinaus ##blick ##en [ . . . ] , sie sind dabei , in g ##e ##wohnlich ##e s ##ch ##la ##f ##m ##utzen zu de ##gen ##erie ##ren und [ . . . ] sie wollen nicht die direkt ##iven des z ##k erfullen . ( s . 13 ##4 )'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY2XrhyRem2O"
      },
      "source": [
        "To re-assemble words from the extracted tokens, use the `BertTokenizer.detokenize` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toBXQSrgemRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da14c53-1ce5-4bc8-ffd2-6f3c133181a4"
      },
      "source": [
        "words = en_tokenizer.detokenize(token_batch)\n",
        "tf.strings.reduce_join(words, separator=' ', axis=-1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
              "array([b'fotos von quebec - dacher von quebec',\n",
              "       b'april 2007 in einer nicht so schockierenden , aber sehr relevanten umfrage , entdeckte btobonline das die meisten e - mail vermarkter \\xe2\\x80\\x93 besonders die auf der business to business seite - verzichten weiterhin auf die prufung ihrer kampagnen bevor sie sie senden .',\n",
              "       b'tschekisten konnen nicht uber ihre eigene nase hinausblicken [ . . . ] , sie sind dabei , in gewohnliche schlafmutzen zu degenerieren und [ . . . ] sie wollen nicht die direktiven des zk erfullen . ( s . 134 )'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIZWWy_iueQY"
      },
      "source": [
        "> Note: `BertTokenizer.tokenize`/`BertTokenizer.detokenize` does not round\n",
        "trip losslessly. The result of `detokenize` will not, in general, have the\n",
        "same content or offsets as the input to `tokenize`. This is because of the\n",
        "\"basic tokenization\" step, that splits the strings into words before\n",
        "applying the `WordpieceTokenizer`, includes irreversible\n",
        "steps like lower-casing and splitting on punctuation. `WordpieceTokenizer`\n",
        "on the other hand **is** reversible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bN30iCexTPY"
      },
      "source": [
        "## Customization and export\n",
        "\n",
        "This tutorial builds the text tokenizer and detokenizer used by the [Transformer](https://tensorflow.org/tutorials/text/transformer) tutorial. This section adds methods and processing steps to simplify that tutorial, and exports the tokenizers using `tf.saved_model` so they can be imported by the other tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wpc7oFkwgni"
      },
      "source": [
        "### Custom tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaUR9hHj0PUy"
      },
      "source": [
        "The downstream tutorials both expect the tokenized text to include `[START]` and `[END]` tokens.\n",
        "\n",
        "The `reserved_tokens` reserve space at the beginning of the vocabulary, so `[START]` and `[END]` have the same indexes for both languages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyyoa5De0WQu"
      },
      "source": [
        "START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n",
        "END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n",
        "\n",
        "def add_start_end(ragged):\n",
        "  count = ragged.bounding_shape()[0]\n",
        "  starts = tf.fill([count,1], START)\n",
        "  ends = tf.fill([count,1], END)\n",
        "  return tf.concat([starts, ragged, ends], axis=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrZjQIwZ6NHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10c821d-7f21-4125-9ef9-217ec969fa38"
      },
      "source": [
        "words = en_tokenizer.detokenize(add_start_end(token_batch))\n",
        "tf.strings.reduce_join(words, separator=' ', axis=-1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
              "array([b'[START] fotos von quebec - dacher von quebec [END]',\n",
              "       b'[START] april 2007 in einer nicht so schockierenden , aber sehr relevanten umfrage , entdeckte btobonline das die meisten e - mail vermarkter \\xe2\\x80\\x93 besonders die auf der business to business seite - verzichten weiterhin auf die prufung ihrer kampagnen bevor sie sie senden . [END]',\n",
              "       b'[START] tschekisten konnen nicht uber ihre eigene nase hinausblicken [ . . . ] , sie sind dabei , in gewohnliche schlafmutzen zu degenerieren und [ . . . ] sie wollen nicht die direktiven des zk erfullen . ( s . 134 ) [END]'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMmHS5VT_suH"
      },
      "source": [
        "### Custom detokenization\n",
        "\n",
        "Before exporting the tokenizers there are a couple of things you can cleanup for the downstream tutorials:\n",
        "\n",
        "1. They want to generate clean text output, so drop reserved tokens like `[START]`, `[END]` and `[PAD]`.\n",
        "2. They're interested in complete strings, so apply a string join along the `words` axis of the result.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9vXUQPX1ZFA"
      },
      "source": [
        "def cleanup_text(reserved_tokens, token_txt):\n",
        "  # Drop the reserved tokens, except for \"[UNK]\".\n",
        "  bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != \"[UNK]\"]\n",
        "  bad_token_re = \"|\".join(bad_tokens)\n",
        "    \n",
        "  bad_cells = tf.strings.regex_full_match(token_txt, bad_token_re)\n",
        "  result = tf.ragged.boolean_mask(token_txt, ~bad_cells)\n",
        "\n",
        "  # Join them into strings.\n",
        "  result = tf.strings.reduce_join(result, separator=' ', axis=-1)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMSpZUV7sQYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1035c7-7e01-4a50-b648-b4eff202ff3d"
      },
      "source": [
        "en_examples.numpy()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'Fotos von Quebec - D\\xc3\\xa4cher von Quebec',\n",
              "       b'April 2007 In einer nicht so schockierenden, aber sehr relevanten Umfrage, entdeckte BtoBonline das die meisten E-Mail Vermarkter \\xe2\\x80\\x93 besonders die auf der business to business Seite- verzichten weiterhin auf die Pr\\xc3\\xbcfung Ihrer Kampagnen bevor sie Sie senden.',\n",
              "       b'Tschekisten k\\xc3\\xb6nnen nicht \\xc3\\xbcber ihre eigene Nase hinausblicken [...], sie sind dabei, in gew\\xc3\\xb6hnliche Schlafm\\xc3\\xbctzen zu degenerieren und [...] sie wollen nicht die Direktiven des ZK erf\\xc3\\xbcllen. (S. 134)'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB3MJhNvkuBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70427298-9301-4714-cee2-eb3fe8729265"
      },
      "source": [
        "token_batch = en_tokenizer.tokenize(en_examples).merge_dims(-2,-1)\n",
        "words = en_tokenizer.detokenize(token_batch)\n",
        "words"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'fotos', b'von', b'quebec', b'-', b'dacher', b'von', b'quebec'], [b'april', b'2007', b'in', b'einer', b'nicht', b'so', b'schockierenden', b',', b'aber', b'sehr', b'relevanten', b'umfrage', b',', b'entdeckte', b'btobonline', b'das', b'die', b'meisten', b'e', b'-', b'mail', b'vermarkter', b'\\xe2\\x80\\x93', b'besonders', b'die', b'auf', b'der', b'business', b'to', b'business', b'seite', b'-', b'verzichten', b'weiterhin', b'auf', b'die', b'prufung', b'ihrer', b'kampagnen', b'bevor', b'sie', b'sie', b'senden', b'.'], [b'tschekisten', b'konnen', b'nicht', b'uber', b'ihre', b'eigene', b'nase', b'hinausblicken', b'[', b'.', b'.', b'.', b']', b',', b'sie', b'sind', b'dabei', b',', b'in', b'gewohnliche', b'schlafmutzen', b'zu', b'degenerieren', b'und', b'[', b'.', b'.', b'.', b']', b'sie', b'wollen', b'nicht', b'die', b'direktiven', b'des', b'zk', b'erfullen', b'.', b'(', b's', b'.', b'134', b')']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED5rMeZE6HT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42df7e7-cdae-4cf1-ffce-9289767f2c33"
      },
      "source": [
        "cleanup_text(reserved_tokens, words).numpy()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'fotos von quebec - dacher von quebec',\n",
              "       b'april 2007 in einer nicht so schockierenden , aber sehr relevanten umfrage , entdeckte btobonline das die meisten e - mail vermarkter \\xe2\\x80\\x93 besonders die auf der business to business seite - verzichten weiterhin auf die prufung ihrer kampagnen bevor sie sie senden .',\n",
              "       b'tschekisten konnen nicht uber ihre eigene nase hinausblicken [ . . . ] , sie sind dabei , in gewohnliche schlafmutzen zu degenerieren und [ . . . ] sie wollen nicht die direktiven des zk erfullen . ( s . 134 )'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEfEdRi11Re4"
      },
      "source": [
        "### Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFuo1KZjpEPR"
      },
      "source": [
        "The following code block builds a `CustomTokenizer` class to contain the `text.BertTokenizer` instances, the custom logic, and the `@tf.function` wrappers required for export. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1q1hCpH72Vj"
      },
      "source": [
        "class CustomTokenizer(tf.Module):\n",
        "  def __init__(self, reserved_tokens, vocab_path):\n",
        "    self.tokenizer = text.BertTokenizer(vocab_path, lower_case=True)\n",
        "    self._reserved_tokens = reserved_tokens\n",
        "    self._vocab_path = tf.saved_model.Asset(vocab_path)\n",
        "\n",
        "    vocab = pathlib.Path(vocab_path).read_text().splitlines()\n",
        "    self.vocab = tf.Variable(vocab)\n",
        "\n",
        "    ## Create the signatures for export:   \n",
        "\n",
        "    # Include a tokenize signature for a batch of strings. \n",
        "    self.tokenize.get_concrete_function(\n",
        "        tf.TensorSpec(shape=[None], dtype=tf.string))\n",
        "    \n",
        "    # Include `detokenize` and `lookup` signatures for:\n",
        "    #   * `Tensors` with shapes [tokens] and [batch, tokens]\n",
        "    #   * `RaggedTensors` with shape [batch, tokens]\n",
        "    self.detokenize.get_concrete_function(\n",
        "        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n",
        "    self.detokenize.get_concrete_function(\n",
        "          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n",
        "\n",
        "    self.lookup.get_concrete_function(\n",
        "        tf.TensorSpec(shape=[None, None], dtype=tf.int64))\n",
        "    self.lookup.get_concrete_function(\n",
        "          tf.RaggedTensorSpec(shape=[None, None], dtype=tf.int64))\n",
        "\n",
        "    # These `get_*` methods take no arguments\n",
        "    self.get_vocab_size.get_concrete_function()\n",
        "    self.get_vocab_path.get_concrete_function()\n",
        "    self.get_reserved_tokens.get_concrete_function()\n",
        "    \n",
        "  @tf.function\n",
        "  def tokenize(self, strings):\n",
        "    enc = self.tokenizer.tokenize(strings)\n",
        "    # Merge the `word` and `word-piece` axes.\n",
        "    enc = enc.merge_dims(-2,-1)\n",
        "    enc = add_start_end(enc)\n",
        "    return enc\n",
        "\n",
        "  @tf.function\n",
        "  def detokenize(self, tokenized):\n",
        "    words = self.tokenizer.detokenize(tokenized)\n",
        "    return cleanup_text(self._reserved_tokens, words)\n",
        "\n",
        "  @tf.function\n",
        "  def lookup(self, token_ids):\n",
        "    return tf.gather(self.vocab, token_ids)\n",
        "\n",
        "  @tf.function\n",
        "  def get_vocab_size(self):\n",
        "    return tf.shape(self.vocab)[0]\n",
        "\n",
        "  @tf.function\n",
        "  def get_vocab_path(self):\n",
        "    return self._vocab_path\n",
        "\n",
        "  @tf.function\n",
        "  def get_reserved_tokens(self):\n",
        "    return tf.constant(self._reserved_tokens)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHzEnTQM6nBD"
      },
      "source": [
        "Build a `CustomTokenizer` for each language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU8yFBCSruz4"
      },
      "source": [
        "tokenizers = tf.Module()\n",
        "tokenizers.de = CustomTokenizer(reserved_tokens, '/content/drive/MyDrive/MT/de_vocab.txt')\n",
        "tokenizers.en = CustomTokenizer(reserved_tokens, '/content/drive/MyDrive/MT/en_vocab.txt')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYfrmDhy6syT"
      },
      "source": [
        "Export the tokenizers as a `saved_model`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aieDGooa9ms7"
      },
      "source": [
        "model_name = 'paracrawl_de_en_converter'\n",
        "tf.saved_model.save(tokenizers, model_name)\n",
        "model_nameDrive = '/content/drive/MyDrive/MT/paracrawl_de_en_converter'\n",
        "tf.saved_model.save(tokenizers, model_nameDrive)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoCMz2Fm61v6"
      },
      "source": [
        "Reload the `saved_model` and test the methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SB_BHwqsHkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6d1958-bf27-4443-b176-b0c6b137acd3"
      },
      "source": [
        "reloaded_tokenizers = tf.saved_model.load(model_name)\n",
        "reloaded_tokenizers.en.get_vocab_size().numpy()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Ze3WL3816x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62cda41-4841-47c9-9bc7-d564afcf6381"
      },
      "source": [
        "tokens = reloaded_tokenizers.en.tokenize(['Hello TensorFlow!'])\n",
        "tokens.numpy()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   2,   49, 1854, 1061,   61, 3722, 1285, 1129, 5978,    4,    3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9o93bzcuhyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecdf9c9-260c-4fe6-b971-f491641847c0"
      },
      "source": [
        "text_tokens = reloaded_tokenizers.en.lookup(tokens)\n",
        "text_tokens"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'[START]', b'h', b'##ell', b'##o', b't', b'##ens', b'##or', b'##f', b'##low', b'!', b'[END]']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0205N_8dDT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47480705-6dfb-4678-ca48-278b14292190"
      },
      "source": [
        "round_trip = reloaded_tokenizers.en.detokenize(tokens)\n",
        "\n",
        "print(round_trip.numpy()[0].decode('utf-8'))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello tensorflow !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSKFDQoBjnNp"
      },
      "source": [
        "Archive it for the [translation tutorials](https://tensorflow.org/tutorials/text/transformer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY0SoE3Yj2it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6d9b95-3a89-4e02-f90b-40e6b4a7464c"
      },
      "source": [
        "!zip -r {model_name}.zip {model_name}\n",
        "!du -h *.zip\n",
        "!zip -r {model_nameDrive}.zip {model_nameDrive}\n",
        "!du -h *.zip"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: paracrawl_de_en_converter/ (stored 0%)\n",
            "  adding: paracrawl_de_en_converter/assets/ (stored 0%)\n",
            "  adding: paracrawl_de_en_converter/assets/en_vocab.txt (deflated 53%)\n",
            "  adding: paracrawl_de_en_converter/assets/de_vocab.txt (deflated 50%)\n",
            "  adding: paracrawl_de_en_converter/saved_model.pb (deflated 91%)\n",
            "  adding: paracrawl_de_en_converter/variables/ (stored 0%)\n",
            "  adding: paracrawl_de_en_converter/variables/variables.data-00000-of-00001 (deflated 47%)\n",
            "  adding: paracrawl_de_en_converter/variables/variables.index (deflated 33%)\n",
            "184K\tparacrawl_de_en_converter.zip\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/variables/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/variables/variables.data-00000-of-00001 (deflated 47%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/variables/variables.index (deflated 33%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/assets/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/assets/de_vocab.txt (deflated 50%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/assets/en_vocab.txt (deflated 53%)\n",
            "  adding: content/drive/MyDrive/MT/paracrawl_de_en_converter/saved_model.pb (deflated 91%)\n",
            "184K\tparacrawl_de_en_converter.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Synq0RekAXe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16a45fc-2152-41e7-c93b-06afe94b9a84"
      },
      "source": [
        "!du -h *.zip"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "184K\tparacrawl_de_en_converter.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtmGkGBuGHa2"
      },
      "source": [
        "<a id=\"algorithm\"></a>\n",
        "\n",
        "## Optional: The algorithm\n",
        "\n",
        "\n",
        "It's worth noting here that there are two versions of the WordPiece algorithm: Bottom-up and top-down. In both cases goal is the same: \"Given a training corpus and a number of desired\n",
        "tokens D, the optimization problem is to select D wordpieces such that the resulting corpus is minimal in the\n",
        "number of wordpieces when segmented according to the chosen wordpiece model.\"\n",
        "\n",
        "The  original [bottom-up WordPiece algorithm](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf), is based on [byte-pair encoding](https://towardsdatascience.com/byte-pair-encoding-the-dark-horse-of-modern-nlp-eb36c7df4f10). Like BPE, It starts with the alphabet, and iteratively combines common bigrams to form word-pieces and words.\n",
        "\n",
        "TensorFlow Text's vocabulary generator follows the top-down implementation from [BERT](https://arxiv.org/pdf/1810.04805.pdf). Starting with words and breaking them down into smaller components until they hit the frequency threshold, or can't be broken down further. The next section describes this in detail. For Japanese, Chinese and Korean this top-down approach doesn't work since there are no explicit word units to start with. For those you need a [different approach](https://tfhub.dev/google/zh_segmentation/1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLA2QhffYEo0"
      },
      "source": [
        "### Choosing the vocabulary\n",
        "\n",
        "The top-down WordPiece generation algorithm takes in a set of (word, count) pairs and a threshold `T`, and returns a vocabulary `V`.\n",
        "\n",
        "The algorithm is iterative. It is run for `k` iterations, where typically `k = 4`, but only the first two are really important. The third and fourth (and beyond) are just identical to the second. Note that each step of the binary search runs the algorithm from scratch for `k` iterations.\n",
        "\n",
        "The iterations described below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqfY0p3PYIKr"
      },
      "source": [
        "#### First iteration\n",
        "\n",
        "1.  Iterate over every word and count pair in the input, denoted as `(w, c)`.\n",
        "2.  For each word `w`, generate every substring, denoted as `s`. E.g., for the\n",
        "    word `human`, we generate `{h, hu, hum, huma,\n",
        "    human, ##u, ##um, ##uma, ##uman, ##m, ##ma, ##man, #a, ##an, ##n}`.\n",
        "3.  Maintain a substring-to-count hash map, and increment the count of each `s`\n",
        "    by `c`. E.g., if we have `(human, 113)` and `(humas, 3)` in our input, the\n",
        "    count of `s = huma` will be `113+3=116`.\n",
        "4.  Once we've collected the counts of every substring, iterate over the `(s,\n",
        "    c)` pairs *starting with the longest `s` first*.\n",
        "5.  Keep any `s` that has a `c > T`. E.g., if `T = 100` and we have `(pers,\n",
        "    231); (dogs, 259); (##rint; 76)`, then we would keep `pers` and `dogs`.\n",
        "6.  When an `s` is kept, subtract off its count from all of its prefixes. This\n",
        "    is the reason for sorting all of the `s` by length in step 4. This is a\n",
        "    critical part of the algorithm, because otherwise words would be double\n",
        "    counted. For example, let's say that we've kept `human` and we get to\n",
        "    `(huma, 116)`. We know that `113` of those `116` came from `human`, and `3`\n",
        "    came from `humas`. However, now that `human` is in our vocabulary, we know\n",
        "    we will never segment `human` into `huma ##n`. So once `human` has been\n",
        "    kept, then `huma` only has an *effective* count of `3`.\n",
        "\n",
        "This algorithm will generate a set of word pieces `s` (many of which will be\n",
        "whole words `w`), which we *could* use as our WordPiece vocabulary.\n",
        "\n",
        "However, there is a problem: This algorithm will severely overgenerate word\n",
        "pieces. The reason is that we only subtract off counts of prefix tokens.\n",
        "Therefore, if we keep the word `human`, we will subtract off the count for `h,\n",
        "hu, hu, huma`, but not for `##u, ##um, ##uma, ##uman` and so on. So we might\n",
        "generate both `human` and `##uman` as word pieces, even though `##uman` will\n",
        "never be applied.\n",
        "\n",
        "So why not subtract off the counts for every *substring*, not just every\n",
        "*prefix*? Because then we could end up subtracting off the counts multiple\n",
        "times. Let's say that we're processing `s` of length 5 and we keep both\n",
        "`(##denia, 129)` and `(##eniab, 137)`, where `65` of those counts came from the\n",
        "word `undeniable`. If we subtract off from *every* substring, we would subtract\n",
        "`65` from the substring `##enia` twice, even though we should only subtract\n",
        "once. However, if we only subtract off from prefixes, it will correctly only be\n",
        "subtracted once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNCtKR8xT9wX"
      },
      "source": [
        "#### Second (and third ...) iteration\n",
        "\n",
        "To solve the overgeneration issue mentioned above, we perform multiple\n",
        "iterations of the algorithm.\n",
        "\n",
        "Subsequent iterations are identical to the first, with one important\n",
        "distinction: In step 2, instead of considering *every* substring, we apply the\n",
        "WordPiece tokenization algorithm using the vocabulary from the previous\n",
        "iteration, and only consider substrings which *start* on a split point.\n",
        "\n",
        "For example, let's say that we're performing step 2 of the algorithm and\n",
        "encounter the word `undeniable`. In the first iteration, we would consider every\n",
        "substring, e.g., `{u, un, und, ..., undeniable, ##n, ##nd, ..., ##ndeniable,\n",
        "...}`.\n",
        "\n",
        "Now, for the second iteration, we will only consider a subset of these. Let's\n",
        "say that after the first iteration, the relevant word pieces are:\n",
        "\n",
        "`un, ##deni, ##able, ##ndeni, ##iable`\n",
        "\n",
        "The WordPiece algorithm will segment this into `un ##deni ##able` (see the\n",
        "section [Applying WordPiece](#applying-wordpiece) for more information). In this\n",
        "case, we will only consider substrings that *start* at a segmentation point. We\n",
        "will still consider every possible *end* position. So during the second\n",
        "iteration, the set of `s` for `undeniable` is:\n",
        "\n",
        "`{u, un, und, unden, undeni, undenia, undeniab, undeniabl,\n",
        "undeniable, ##d, ##de, ##den, ##deni, ##denia, ##deniab, ##deniabl\n",
        ", ##deniable, ##a, ##ab, ##abl, ##able}`\n",
        "\n",
        "The algorithm is otherwise identical. In this example, in the first iteration,\n",
        "the algorithm produces the suprious tokens `##ndeni` and `##iable`. Now, these\n",
        "tokens are never considered, so they will not be generated by the second\n",
        "iteration. We perform several iterations just to make sure the results converge\n",
        "(although there is no literal convergence guarantee).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdUkqe84YQA5"
      },
      "source": [
        "### Applying WordPiece\n",
        "\n",
        "<a id=\"applying_wordpiece\"></a>\n",
        "\n",
        "Once a WordPiece vocabulary has been generated, we need to be able to apply it\n",
        "to new data. The algorithm is a simple greedy longest-match-first application.\n",
        "\n",
        "For example, consider segmenting the word `undeniable`.\n",
        "\n",
        "We first lookup `undeniable` in our WordPiece dictionary, and if it's present,\n",
        "we're done. If not, we decrement the end point by one character, and repeat,\n",
        "e.g., `undeniabl`.\n",
        "\n",
        "Eventually, we will either find a subtoken in our vocabulary, or get down to a\n",
        "single character subtoken. (In general, we assume that every character is in our\n",
        "vocabulary, although this might not be the case for rare Unicode characters. If\n",
        "we encounter a rare Unicode character that's not in the vocabulary we simply map\n",
        "the entire word to `<unk>`).\n",
        "\n",
        "In this case, we find `un` in our vocabulary. So that's our first word piece.\n",
        "Then we jump to the end of `un` and repeat the processing, e.g., try to find\n",
        "`##deniable`, then `##deniabl`, etc. This is repeated until we've segmented the\n",
        "entire word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjRQKQzpYMl2"
      },
      "source": [
        "### Intuition\n",
        "\n",
        "Intuitively, WordPiece tokenization is trying to satisfy two different\n",
        "objectives:\n",
        "\n",
        "1.  Tokenize the data into the *least* number of pieces as possible. It is\n",
        "    important to keep in mind that the WordPiece algorithm does not \"want\" to\n",
        "    split words. Otherwise, it would just split every word into its characters,\n",
        "    e.g., `human -> {h, ##u, ##m, ##a, #n}`. This is one critical thing that\n",
        "    makes WordPiece different from morphological splitters, which will split\n",
        "    linguistic morphemes even for common words (e.g., `unwanted -> {un, want,\n",
        "    ed}`).\n",
        "\n",
        "2.  When a word does have to be split into pieces, split it into pieces that\n",
        "    have maximal counts in the training data. For example, the reason why the\n",
        "    word `undeniable` would be split into `{un, ##deni, ##able}` rather than\n",
        "    alternatives like `{unde, ##niab, ##le}` is that the counts for `un` and\n",
        "    `##able` in particular will be very high, since these are common prefixes\n",
        "    and suffixes. Even though the count for `##le` must be higher than `##able`,\n",
        "    the low counts of `unde` and `##niab` will make this a less \"desirable\"\n",
        "    tokenization to the algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQZ38Uus-Xv1"
      },
      "source": [
        "## Optional: tf.lookup\n",
        "\n",
        "<a id=\"tf.lookup\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NreDSRmJNG_h"
      },
      "source": [
        "If you need access to, or more control over the vocabulary it's worth noting that you can build the lookup table yourself and pass that to `BertTokenizer`.\n",
        "\n",
        "When you pass a string, `BertTokenizer` does the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thAF1DzQOQXl"
      },
      "source": [
        "de_lookup = tf.lookup.StaticVocabularyTable(\n",
        "    num_oov_buckets=1,\n",
        "    initializer=tf.lookup.TextFileInitializer(\n",
        "        filename='de_vocab.txt',\n",
        "        key_dtype=tf.string,\n",
        "        key_index = tf.lookup.TextFileIndex.WHOLE_LINE,\n",
        "        value_dtype = tf.int64,\n",
        "        value_index=tf.lookup.TextFileIndex.LINE_NUMBER)) \n",
        "de_tokenizer = text.BertTokenizer(de_lookup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERY4FYN7O66R"
      },
      "source": [
        "Now you have direct access to the lookup table used in the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "337_DcAMOs6N"
      },
      "source": [
        "de_lookup.lookup(tf.constant(['é', 'um', 'uma', 'para', 'não']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdZ82x5mPDE9"
      },
      "source": [
        "You don't need to use a vocabulary file, `tf.lookup` has other initializer options. If you have the vocabulary in memory you can use `lookup.KeyValueTensorInitializer`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzkrmO9H-b9i"
      },
      "source": [
        "de_lookup = tf.lookup.StaticVocabularyTable(\n",
        "    num_oov_buckets=1,\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=pt_vocab,\n",
        "        values=tf.range(len(pt_vocab), dtype=tf.int64))) \n",
        "de_tokenizer = text.BertTokenizer(de_lookup)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}